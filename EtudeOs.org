* Bifrost - Etude du fonctionnement d'un système d'exploitation

Ce document a pour but de décrire simplement le fonctionnement d'un système d'exploitation simple, puis
d'imaginer une manière de concevoir un OS distribué à partir de ces informations.

Note 1 : je pars du principe qu'on va travailler sur un OS avec certain certaines caractéristiques ordinaires,
par exemple certains OS laissent le userland gérer beaucoup plus de choses quant à la gestion de processus...
Ici, on reste sur un schéma classique : le noyau s'occupe des processus, threads et leur ordonnancement.

Note 2 : ma principale référence sera le tuto rédigé en Français "pepin os" car il donne une idée claire des principaux
mécanismes abordés ici.

** Introduction

On peut distinguer deux grandes parties :
 - Le noyau
 - Le userland (parce que "monde utilisateur" c'est moche et plus long)

Le userland est composé de processus, cloisonnés, c'est à dire que grâce à l'utilisation de la mémoire virtuelle,
ils pensent être seuls sur la machine, et avoir accès à toute la mémoire. Un processus ne peut cependant pas
en écraser un autre, à moins de le faire volontairement via un appel système. Un processus peut également être soumis
à des règles de sécurité.
 
Le noyau peut avoir plusieurs rôles suivant ce qu'on lui demande de faire ou non. Certains ont pour but
de prendre en charge un grand nombre de fonctionnalités, d'autres tout à fait le contraire.

Les deux types de noyaux principaux sont les noyaux monolithiques et les micronoyaux.

*** Micronoyau

Un micronoyau va être petit, et se contenter de mettre à disposition que peu de fonctionnalités : gestion de la mémoire,
des threads et de leur ordonancement, des IPC (communications interprocessus).

Le reste des fonctionnalités (drivers, systèmes de fichiers, ...) s'exécutent dans le userland.

L'intérêt est d'avoir peu de code, donc moins de bugs, et de profiter du cloisonnement qu'offre l'utilisation de
processus pour avoir un système plus stable (exemple : si un driver crash, plutôt que de faire crasher le système,
on le relance simplement).
L'avantage est également dans la sécurité, il est plus facile de contrôler les accès des processus, le noyau, lui 
peut tout faire.

L'inconvéniant est sans doute dans les performances, que ce soit concernant l'accès au hardware
ou tout ce qui concerne la sécurité (plus de vérifications nécessaire). Il faut alors trouver un moyen de 
limiter le nombre d'appels systèmes, je n'ai pas encore étudié ces problématiques.

Note : je pense qu'il est possible de permettre à un programme s'exécutant dans le userland d'accéder directement au
hardware.

Exemple de OS : Minix

*** Noyau monolithique

Au contraire, un noyau monolitique va regrouper de nombreuses fonctionnalités. Par exemple, le noyau Linux intègre directement
le support d'un système de fichier.

L'avantage est, là aussi, sans doute dans les performances. Le noyau peut accéder rapidement au hardware, et sans avoir
besoin de faire des vérifications de sécurité (par définition, le noyau peut tout faire).

L'inconvéniant est dans la stabilité : un bug, déférencement de pointeur ou autre, et le système crash. Le noyau
étant plus gros, il y a plus de risque de bug. La surface d'attaque est également plus grande et plus compliquée
à contrôler.

** Feuille de route pour la création d'un noyau simple

On retrouve principalement les éléments suivants lors de la création d'un noyau (certains de ces éléments seront
détaillés dans les prochaines parties) :
 - Utilisation d'un bootloader, exemple : GRUB, son rôle va être de charger le noyau, passer en mode protéger, donner la main du noyau...
 - Initialiser la GDT : Global Descriptor Table
 - Initialisation de l'IDT : Interrupt Descriptor Table
 - Programmation du PIC : Programmable Interrupt Controller
 - Initialisation du gestionnaire de mémoire physique (opération purement dev, on ne touche pas au matériel)
 - Initialisation de la mémoire virtuelle et activation de la pagination
 
Une fois cette dernière opération effectuée, il reste à initialiser ce qui compose le reste du noyau (drivers,
memory pool...).

** Création d'un noyau - Programmation du CPU

La création d'un noyau commence par la programmation du CPU, afin d'activer certains mécanismes mis à disposition
par le processeur et dont nous avons besoin (par exemple, la pagination).

*** Global Descriptor Table

GRUB passant le processeur en mode protégé, on passe en adressage "logique", c'est à dire qu'une adresse manipulée par le programmeur
se compose d'un sélecteur de segment et d'un offset. Ce sélecteur de segment fait référence à une entrée dans un tableau nommé "Global Descriptor Table".
Celui-ci décrit plusieurs segments, en spécifiant leur type, avec quel niveau de privilège peut-on les utiliser, etc...

Par exemple, avec le noyau LtKernel, on a :
 - 1 Segment de code et un segment de données/pile pour le noyau, couvrent toute la RAM, accessibles qu'en ring 0
 - 1 Segment de code et un segment de données/pile pour le userland, couvrent toute la RAM, accessibles en ring <= 3
 - Un Segment TSS, faisant référence à la structure TSS, utilisée dans le mécanisme de commutation de tâche

Ce tableau est renseigné auprès du processeur via l'instruction ~lgdt~

Plus de détails ici : [[http://a.michelizza.free.fr/pmwiki.php?n=TutoOS.ProtectedMode][Pepin Os - Addresser la mémoire en mode protégé]]

*** Programmable Interrupt Controller

Le controleur d'interruption programmable permet de faire deux choses :
 - indiquer quelles interruptions masquer ou non : si on masque l'interruption du périphérique clavier, alors le processeur ne sera pas notifié
 des événements provenant du clavier. On peut donc demander à être notifié, ou pas, de tel ou tel périphérique.
 - indiquer sur "range" de l'IDT sont stockées les routines à appeler en cas d'interruption matérielles (IDT, voir la partie suivante).

Plus de détails ici : [[http://a.michelizza.free.fr/pmwiki.php?n=TutoOS.Int][Pepin Os - Un chipset pour gérer les interruptions matérielles : le 8259A]]
 
*** Interrupt Descriptor Table

La table d'interruptions, ou Interrupt Descriptor Table, représente un tableau contenant des pointeurs sur fonction. On retrouve 3 types
de fonction dans cette table :
 - les exceptions processeur : la routine à appeler en cas de défaut de page, de breakpoint (~int 3~), ...
 - les interruptions matérielles : horloge CPU, clavier, port série...
 - les interruptions logicielles : les appels système
 
Note : quand une interruption est déclanchée, le processeur bascule sur une pile noyau, indiquée dans le segment TSS, si la tâche courante
tourne en utilisateur. Dans tous les cas, le contenu de plusieurs registres sont placés sur la pile noyau afin de pouvoir revenir
à la tâche interrompu une fois l'interruption traitée.

*** Gestionnaire de mémoire physique

Cela ne concerne pas la programmation du CPU, mais c'est tout de même nécessaire : il faut un outil permettant de savoir quelles pages physique
sont libres en RAM. Une solution est l'utilisation d'un bitmap.

Note : GRUB nous file un pointeur sur une structure comportant des info dont la taille de la RAM.

*** Mémoire virtuelle et pagination

L'utilisation de la mémoire virtuelle permet une utilisation plus souple de la mémoire et donne plusieurs avantages :
 - Deux processus ne peuvent pas accéder à la même mémoire physique involontairement
 - Même avec 2Go de RAM on peut faire croire au processus qu'il en a 4Go
 - Si une page n'est pas en mémoire, le défaut de page permet de régler le problème...
 - et on doit pouvoir en trouver d'autres...
 
Son mécanisme est simple : ici aussi le processeur se base sur une table, et même sur plusieurs : un répertoire de table pages,
et des tables de pages.
Chaque entrée du répertoire de table pages pointe sur une table de page.
Chaque entrée d'une table de page pointe sur une page.

Une adresse va se résoudre de cette manière : 
 - les 10 premiers bits représentent un offset dans le répertoire de pages.
 - les 10 suivants représentent un offset dans la table récupérée.
 - les 12 derniers représentent un offset sur la page (donc l'adresse physique récupérée + cet offset = destination physique)
 
Note 1 : on peut être amené à modifier une entrée de répertoire ou de table, mais on a aucune adresse virtuelle pour y accéder...
Du coup, à la mise en place de la pagination, on place l'adresse physique du début du répertoire dans la dernière entrée du répertoire.
Et on fait de même avec les tables. De cette manière, en créant l'adresse virtuelle adéquate, on peut tomber sur l'entrée qui nous intéresse.

Note 2 : afin que chaque processus ait son propre espace d'adressage, on change de répertoire de pages à chaque commutation de tâche.

Note 3 : afin que le code noyau fonctionne correctement, le 1er Go, réservé au noyau, utilise l'"identity mapping", c'est à dire que 
l'adresse virtuelle 0 == l'adresse physique 0, etc... sur 1Go de mémoire.

Plus de détails ici : [[http://a.michelizza.free.fr/pmwiki.php?n=TutoOS.Mm][Pepin Os - Mémoire virtuelle et mémoire physique]]

** Les processus et threads

Un processus est une notion abstraite qui va représenter un programme qui s'exécute sur une machine.
Un proecssus est, en pratique, composé d'un ou plusieurs threads. Il a également pour but décrire ce que les threads
ont en commun : la mémoire.

Le thread est l'entité utilisé par l'OS pour représenter un ensemble :
 - du code à exécuter
 - de la mémoire
 - d'autres éléments qui dépendent de l'architecture de l'OS...
 
Ainsi, le noyau ne va pas exécuter un processus, mais un thread, ce dernier partageant sa mémoire avec les autres
threads du même processus.

Lors d'une commutation de tâche, le noyau va enregistrer dans une structure l'état du thread (tous ses registres, l'adresse du répertoire
de pages au cas où on changerait de processus...).

Note : on doit pouvoir distinguer deux types de threads
 - les threads noyau, ils partagent la même mémoire, celle du noyau
 - les threads utilisateur
 
Note 2 : il semble que certains OS implémentent la gestion/l'ordonnancement des threads dans le userland...

** Ordonnancement

Je n'ai pas beaucoup étudier cette partie. Le principe est de déterminer quel thread exécuter, et pendant combien de temps...

** Appels système

Les appels systèmes permettent à un processus utilisateur de demander au noyau d'effectuer une action qu'il ne peut pas faire lui-même,
par exemple un accès à du matériel.

Le fonctionnement d'un appel système repose sur le mécanisme des interruptions déjà vu.
On y rajoute une problématique : le passage de paramètre. Dans le cas de LtKernel, les quelques paramètres,
tel que le numéro de l'appel système ou la chaîne à afficher, sont passé via les registres.
Ceux-ci sont push sur la pile dans le code de l'interruption, permettant ensuite au gestionnaire d'appel système 
de récupérer les paramètres.

Le noyau utilisant le même répertoire de pages que la tâche faisant l'appel système, il a accès aux même données,
et peut ainsi utiliser librement les pointeurs en provenance du userland.

** Communications inter-processus

*** Généralité

Je n'ai pas encore étudié cette partie. Le principe est de pouvoir effectuer un transfert de données entre deux processus, 
qui utilisent donc deux contextes d'adressage différents.

A priori, ça va consister en un appel système, qui va allouer de la mémoire dans le context du processus cible, et y copier les données.
Cela implique, pour le noyau, de copier les données dans un premier temps dans son espace, puis de changer de context d'adressage (celui du processus cible),
et enfin de mettre à jour ce dernier pour accéder aux données récupérée (on doit pouvoir éviter de faire deux copies physiquement, en jouant simplement
avec les tables de pages de la tâche utilisateur).

*** LPC/RPC : Local & Remote Procedure Call

Sujet pas énormément étudié non-plus, mais que j'ai beaucoup utilisé sous Windows. Ces deux mécanismes permettent, respectivement, d'exécuter une fonction
sur un processus d'une machine locale ou distante.

Un processus met à disposition une interface composée d'un ou plusieurs prototypes de fonction. Il possède également l'implémentation de ces fonction. 
Il se déclare à son démarrage en tant que server LPC/RPC.

Un autre processus, distant ou non, va se connecter à l'interface du serveur RPC/LPC. Il connait les prototypes des fonctions en question, et va demander à exécuter
une procédure sur ce processus. La gestion des paramètres, qu'ils soient en "in" ou "out", est prise en compte.

Ceci implique que dans le cas du passage d'un tableau d'octets par exemple, le noyau va devoir effectuer une tâche similaire à ce qui a été expliqué
précédemment (partie Générélité).

** Accès concurrents 

Un système d'exploitation doit mettre à disposition au programmeur un moyen de protéger l'accès aux données qui dont partagées
entre threads et processus.

Côté noyau, je vois deux moyens quant au fonctionnement des mutex/sections critiques :
 - On se base sur une variable globale, un thread qui veut accéder à une ressource protégée vérifie de manière atomique cette variable globale et
 va simplement boucler sur cette vérification jusqu'à ce que la variable soit à 0. L'inconvéniant c'est qu'on prend du temps au CPU pour rien.
 - Se baser également sur une variable globale, sauf que si celle-ci est occupée, on place le thread en attente. L'ordonnanceur essaye de temps
 en temps de relancer le thread, qui se met en pause immédiatement si la ressource n'est toujours pas prête.
 
Côté utilisateur, on ne va pas avoir la possibilité de mettre au pause tout seul le thread, donc deux solutions :
 - Utilisation d'une section critique, on boucle jusqu'à avoir accès à la ressource (je crois que c'est comme ça que sont implémentées les sections critiques
 sous windows en userland)
 - Utilisation d'un mutex, impliquant un appel système : dans ce cas c'est le noyau qui va gérer le problème, en mettant le thread en pause
 
C'est l'idée simple, plusieurs algorithmes permettent de régler les problèmes d'accès concurent, mais généralement on en revient au même :
 - boucler
 - ou mettre le thread en pause

** Idées concernant les allocations dynamique du noyau

Le thème de l'allocation dynamique dans le noyau est important car suivant l'algorithme utilisé, il peut être plus ou moins compliqué,
plus ou moins rapide, plus ou moins sujet à des problèmes de fragmentation...

Le mieux serait de se passer d'allocation dynamique, ou du moins avoir quelque chose de très très simple. On évite des bugs côté noyau.
C'est l'avantage d'utiliser un micronoyau, moins de besoin, on peut peut-être se contenter de bloc de mémoire qui seront réservés à un même utilité.

On doit pouvoir parler des memory pool, de l'algo "classique" d'alloc dynamique comme dans Ltkernel, ou encore de Buddy/Slab allocator.

** Debugging

Avoir la possibilité de debugger le noyau facilement, c'est cool.
Il semble qu'il soit possible de debugger avec GDB ([[http://a.michelizza.free.fr/pmwiki.php?n=TutoOS.Gdb][Déboguer le noyaua vec gdb]]), mais gdb est
vite limité : affichage du code assembleur, de la mémoire et des registres, breakpoint.

Un debugger maison peut avoir plusieurs avantages : 
 - possibilité d'y ajouter une interface graphique pour plus de clareté
 - faire le lien avec le code source
 - mais surtout, afficher des info systèmes, se placer dans le contexte d'un thread, ...
 
Le fonctionnement d'un debugger est simple : on utilise les interruptions 1 (Debug) et 3 (Breakpoint).
L'interruption 3 est déclenchée par le développeut via l'instruction assembleur ~int 3~.
Un bit dans le registre EFLAG permet d'activer le mode "pas à pas", le processeur va alors n'exécuter qu'une instruction et provoquer l'interruption 1.

Concernant le dialogue entre debugger et noyau, le plus simple est l'utilisation du port série, impliquant la réalisation d'un driver très simple.

* Bifrost - Imaginons un OS distribué

** Quelques idées en vrac

*** Reprise du code de LtMicros : programmation du CPU

La partie la plus basse du noyau est la même que pour un noyau classique, cela concerne toute la partie programmation du CPU.
On peut donc imaginer reprendre la base du code de LtMicros, qui est propre et documenté.

*** Implémentation du gestionnaire d'allocation dynamique

On enchaîne ensuite avec la gestion des allocations du noyau. Ce dernier en aura sans doute besoin au début, avant même que les mécanismes
permettant d'être un OS distribué soient en place (genre le driver réseau aura sans doute besoin d'allouer de la mémoire...).

Mon but était au départ de se débarrasser d'un système "compliqué", et de se contenter de "memory pool". L'avantage de ces derniers, c'est qu'en
partant du principe qu'on connait à l'avance la taille des quelques rares types de données qu'on va vouloir stocker, on peut créer un allocateur
très simple, sans risque de fragmentation ou autre... On réserve un morceau de mémoire, et on le découpe en bloques de même taille.

Mais dans notre cas, on ne va pas pouvoir rester sur du micronoyau à proprement parler...

Il faut donc trouver un algorithme fiable permettant de gérer simplement les allocations dynamiques. Plusieurs solutions :
 - On commence avec quelque chose de simple : celui de LtKernel, on sait qu'il fonctionne mais on a pas testé ses limites
 - On tente une nouvelle approche plus simple, en partant du principe que le noyau
 
*** Implémentation des processus et threads

Je pense qu'on peut déjà commencer par ces affirmations :
 - On a un seul processus système, constitué de threads noyau (ou pas ??)
 - Les threads noyau s'exécutent sur la machine sur laquelle tourne le noyau
 - Les processus utilisateur est composé de threads
 - Un thread peut être exécuté sur n'importe quel machine du réseau
 
Un thread noyau doit exécuter une tâche que seul le noyau peut exécuter... Il faut déterminer quels types de tâches pourraient nécessiter 
l'utilisation de threads noyau. Et si les threads noyau sont nécessaires, ces tâches peuvent-elles s'exécuter sur une autre machine ?